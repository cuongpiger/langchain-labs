{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:27.654399Z",
     "start_time": "2025-03-31T08:55:27.642309Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:27.727880Z",
     "start_time": "2025-03-31T08:55:27.719031Z"
    }
   },
   "source": [
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain2\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\""
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:27.744547Z",
     "start_time": "2025-03-31T08:55:27.735125Z"
    }
   },
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:27.759236Z",
     "start_time": "2025-03-31T08:55:27.749482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import requests\n",
    "from typing import List\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class CustomEmbedding(Embeddings):\n",
    "    def __init__(self, api_url: str):\n",
    "        self.api_url = api_url\n",
    "        self.dimensions = 768\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embeds multiple texts using the custom embedding API.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.api_url}/embeddings\",\n",
    "            json={\"input\": texts, \"model\": \"all-mpnet-base-v2\"}\n",
    "        )\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        return [item[\"embedding\"] for item in response.json()[\"data\"]]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embeds a single query.\"\"\"\n",
    "        return self.embed_documents([text])[0]"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:27.771507Z",
     "start_time": "2025-03-31T08:55:27.763295Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings_model = CustomEmbedding(\"http://localhost:8000\")\n",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:03:25.495921Z",
     "start_time": "2025-03-31T09:03:25.060255Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_openai import OpenAIEmbeddings",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:03:43.814056Z",
     "start_time": "2025-03-31T09:03:43.772932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings_model = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    openai_api_base=\"http://58.84.3.29.nip.io/v1/maas/sentence-transformers/all-MiniLM-L6-v2/v1\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:03:51.945519Z",
     "start_time": "2025-03-31T09:03:51.045621Z"
    }
   },
   "source": [
    "vector_store = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:03:52.629293Z",
     "start_time": "2025-03-31T09:03:52.614651Z"
    }
   },
   "source": [
    "retriever = vector_store.as_retriever()"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:03:54.179930Z",
     "start_time": "2025-03-31T09:03:53.791640Z"
    }
   },
   "source": "docs = retriever.invoke(\"VKS là gì?\")\n",
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'object': 'error', 'message': 'Token id 41549 is out of vocabulary', 'type': 'BadRequestError', 'param': None, 'code': 400}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[43mretriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mVKS là gì?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_core/retrievers.py:259\u001B[0m, in \u001B[0;36mBaseRetriever.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    257\u001B[0m _kwargs \u001B[38;5;241m=\u001B[39m kwargs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expects_other_args \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_arg_supported:\n\u001B[0;32m--> 259\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_relevant_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_kwargs\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_relevant_documents(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:1073\u001B[0m, in \u001B[0;36mVectorStoreRetriever._get_relevant_documents\u001B[0;34m(self, query, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1071\u001B[0m _kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_kwargs \u001B[38;5;241m|\u001B[39m kwargs\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1073\u001B[0m     docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilarity_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity_score_threshold\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1075\u001B[0m     docs_and_similarities \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1076\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvectorstore\u001B[38;5;241m.\u001B[39msimilarity_search_with_relevance_scores(\n\u001B[1;32m   1077\u001B[0m             query, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs\n\u001B[1;32m   1078\u001B[0m         )\n\u001B[1;32m   1079\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_postgres/vectorstores.py:942\u001B[0m, in \u001B[0;36mPGVector.similarity_search\u001B[0;34m(self, query, k, filter, **kwargs)\u001B[0m\n\u001B[1;32m    931\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Run similarity search with PGVector with distance.\u001B[39;00m\n\u001B[1;32m    932\u001B[0m \n\u001B[1;32m    933\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;124;03m    List of Documents most similar to the query.\u001B[39;00m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_async_engine, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis method must be called without async_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 942\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimilarity_search_by_vector(\n\u001B[1;32m    944\u001B[0m     embedding\u001B[38;5;241m=\u001B[39membedding,\n\u001B[1;32m    945\u001B[0m     k\u001B[38;5;241m=\u001B[39mk,\n\u001B[1;32m    946\u001B[0m     \u001B[38;5;28mfilter\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfilter\u001B[39m,\n\u001B[1;32m    947\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_openai/embeddings/base.py:629\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_query\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21membed_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[1;32m    621\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001B[39;00m\n\u001B[1;32m    622\u001B[0m \n\u001B[1;32m    623\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;124;03m        Embedding for the text.\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_openai/embeddings/base.py:588\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_documents\u001B[0;34m(self, texts, chunk_size)\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[1;32m    587\u001B[0m engine \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeployment)\n\u001B[0;32m--> 588\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_len_safe_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/langchain_openai/embeddings/base.py:483\u001B[0m, in \u001B[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[0;34m(self, texts, engine, chunk_size)\u001B[0m\n\u001B[1;32m    481\u001B[0m batched_embeddings: List[List[\u001B[38;5;28mfloat\u001B[39m]] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[0;32m--> 483\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invocation_params\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    486\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    487\u001B[0m         response \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/openai/resources/embeddings.py:128\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    122\u001B[0m             embedding\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[1;32m    123\u001B[0m                 base64\u001B[38;5;241m.\u001B[39mb64decode(data), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m             )\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[0;32m--> 128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/openai/_base_client.py:1290\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1276\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1278\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1285\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1286\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1287\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1288\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1289\u001B[0m     )\n\u001B[0;32m-> 1290\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/openai/_base_client.py:967\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    965\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/openai/_base_client.py:1071\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1068\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1070\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1071\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1074\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1075\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1079\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1080\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'object': 'error', 'message': 'Token id 41549 is out of vocabulary', 'type': 'BadRequestError', 'param': None, 'code': 400}"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:29.099103Z",
     "start_time": "2025-03-31T08:55:29.088049Z"
    }
   },
   "source": [
    "for d in docs:\n",
    "    print(d)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Người phát triển sản phẩm vCR cũng như song hành cùng anh Dương Mạnh Cường trong quá trình phát triển sản phẩm VKS là anh Nguyễn Thế Vịnh - một Senior System Engineer, hay còn có một cái tên khác là Ninh Văn Chuyên, đã có vợ nhưng vì quá hiền lành nên anh là một nạn nhân của bạo lực gia đình, đây là hình anh Vịnh, hay còn gọi là anh Chuyên <img src=\"https://scontent.fsgn5-3.fna.fbcdn.net/v/t39.30808-6/445003868_2286877194997277_7787465022302515451_n.jpg?_nc_cat=104&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeFCmz9oa5DRQpP6BT8iaVQmTcrck8GaEDVNytyTwZoQNR1GKmbFToFFNqoa0aUYnL5NyY4Rfl9Pltz9VdFMonJi&_nc_ohc=vm8Z7XchnNUQ7kNvgH2CC1Z&_nc_oc=AdgGrGp1fBD-fXi2bhpAowJzJbUUDW692G17TGyuahcv2vvf02LGyzHXJE9EUTg3R3Q&_nc_zt=23&_nc_ht=scontent.fsgn5-3.fna&_nc_gid=j7If0t-o-FvG7vdBXPdz1w&oh=00_AYF3fYcAXjRcAkxeqhLB0A80p-P5LGMr-PMj7YMoHraKSg&oe=67DEE3A6\"></img>'\n",
      "page_content='Người phát triển ra VNGCloud AI Assistant (là một ChatBot Assistant nhằm hỗ trợ khách hàng của VNGCloud) và VKS là anh Dương Mạnh Cường một Software Engineer của VNGCloud, hiện còn độc thân, hình của Cường đây <img src=\" https://avatars.githubusercontent.com/u/40521173?v=4\"></img>'\n",
      "page_content='Người phát triển cũng như là người đứng đằng sau sự thành công của sản phẩm vServer là anh Nguyễn Mạnh Tứ, chưa vợ chưa con, độc thân, đây là hình ảnh của anh Tứ <img src=\"https://scontent.fhan3-2.fna.fbcdn.net/v/t1.6435-9/136142910_3671240586301430_6062072719418469868_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=833d8c&_nc_eui2=AeFpuebo3dCOt-fArif4Mld_-1ztD-AFshj7XO0P4AWyGMrier5Cx3GlRGJ4rbjvpcvt6KZPmuYEiu0NNQhaK_i0&_nc_ohc=wylBOJmzrYkQ7kNvgGBC3pA&_nc_oc=Adgq_4zLXzageSD7RGo-o5Uukq6tE0aRG_0BPpsaeE1Vid8IPPvms3XxAKyNBvGN9bw&_nc_zt=23&_nc_ht=scontent.fhan3-2.fna&_nc_gid=81G_SHnNDdqNGcYwROASFA&oh=00_AYFNgzRrEK2gIVlo2nYpD5LRMXrGhuMrzmz_ISqrKWq3QA&oe=68008D6F\"></img>'\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:29.361508Z",
     "start_time": "2025-03-31T08:55:29.103565Z"
    }
   },
   "source": [
    "docs = retriever.invoke(\"VKS có các version nào\")\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:29.380511Z",
     "start_time": "2025-03-31T08:55:29.367650Z"
    }
   },
   "source": [
    "for d in docs:\n",
    "    print(d, end=\"-----------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Người phát triển sản phẩm vCR cũng như song hành cùng anh Dương Mạnh Cường trong quá trình phát triển sản phẩm VKS là anh Nguyễn Thế Vịnh - một Senior System Engineer, hay còn có một cái tên khác là Ninh Văn Chuyên, đã có vợ nhưng vì quá hiền lành nên anh là một nạn nhân của bạo lực gia đình, đây là hình anh Vịnh, hay còn gọi là anh Chuyên <img src=\"https://scontent.fsgn5-3.fna.fbcdn.net/v/t39.30808-6/445003868_2286877194997277_7787465022302515451_n.jpg?_nc_cat=104&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeFCmz9oa5DRQpP6BT8iaVQmTcrck8GaEDVNytyTwZoQNR1GKmbFToFFNqoa0aUYnL5NyY4Rfl9Pltz9VdFMonJi&_nc_ohc=vm8Z7XchnNUQ7kNvgH2CC1Z&_nc_oc=AdgGrGp1fBD-fXi2bhpAowJzJbUUDW692G17TGyuahcv2vvf02LGyzHXJE9EUTg3R3Q&_nc_zt=23&_nc_ht=scontent.fsgn5-3.fna&_nc_gid=j7If0t-o-FvG7vdBXPdz1w&oh=00_AYF3fYcAXjRcAkxeqhLB0A80p-P5LGMr-PMj7YMoHraKSg&oe=67DEE3A6\"></img>'-----------------------page_content='Người phát triển cũng như là người đứng đằng sau sự thành công của sản phẩm vServer là anh Nguyễn Mạnh Tứ, chưa vợ chưa con, độc thân, đây là hình ảnh của anh Tứ <img src=\"https://scontent.fhan3-2.fna.fbcdn.net/v/t1.6435-9/136142910_3671240586301430_6062072719418469868_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=833d8c&_nc_eui2=AeFpuebo3dCOt-fArif4Mld_-1ztD-AFshj7XO0P4AWyGMrier5Cx3GlRGJ4rbjvpcvt6KZPmuYEiu0NNQhaK_i0&_nc_ohc=wylBOJmzrYkQ7kNvgGBC3pA&_nc_oc=Adgq_4zLXzageSD7RGo-o5Uukq6tE0aRG_0BPpsaeE1Vid8IPPvms3XxAKyNBvGN9bw&_nc_zt=23&_nc_ht=scontent.fhan3-2.fna&_nc_gid=81G_SHnNDdqNGcYwROASFA&oh=00_AYFNgzRrEK2gIVlo2nYpD5LRMXrGhuMrzmz_ISqrKWq3QA&oe=68008D6F\"></img>'-----------------------page_content='Người phát triển ra VNGCloud AI Assistant (là một ChatBot Assistant nhằm hỗ trợ khách hàng của VNGCloud) và VKS là anh Dương Mạnh Cường một Software Engineer của VNGCloud, hiện còn độc thân, hình của Cường đây <img src=\" https://avatars.githubusercontent.com/u/40521173?v=4\"></img>'-----------------------"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:29.639936Z",
     "start_time": "2025-03-31T08:55:29.385925Z"
    }
   },
   "source": [
    "docs = retriever.invoke(\"So sánh private cluster và public cluster\")\n",
    "for d in docs:\n",
    "    print(d, end=\"-----------------------\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Người phát triển sản phẩm vCR cũng như song hành cùng anh Dương Mạnh Cường trong quá trình phát triển sản phẩm VKS là anh Nguyễn Thế Vịnh - một Senior System Engineer, hay còn có một cái tên khác là Ninh Văn Chuyên, đã có vợ nhưng vì quá hiền lành nên anh là một nạn nhân của bạo lực gia đình, đây là hình anh Vịnh, hay còn gọi là anh Chuyên <img src=\"https://scontent.fsgn5-3.fna.fbcdn.net/v/t39.30808-6/445003868_2286877194997277_7787465022302515451_n.jpg?_nc_cat=104&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeFCmz9oa5DRQpP6BT8iaVQmTcrck8GaEDVNytyTwZoQNR1GKmbFToFFNqoa0aUYnL5NyY4Rfl9Pltz9VdFMonJi&_nc_ohc=vm8Z7XchnNUQ7kNvgH2CC1Z&_nc_oc=AdgGrGp1fBD-fXi2bhpAowJzJbUUDW692G17TGyuahcv2vvf02LGyzHXJE9EUTg3R3Q&_nc_zt=23&_nc_ht=scontent.fsgn5-3.fna&_nc_gid=j7If0t-o-FvG7vdBXPdz1w&oh=00_AYF3fYcAXjRcAkxeqhLB0A80p-P5LGMr-PMj7YMoHraKSg&oe=67DEE3A6\"></img>'-----------------------page_content='Người phát triển cũng như là người đứng đằng sau sự thành công của sản phẩm vServer là anh Nguyễn Mạnh Tứ, chưa vợ chưa con, độc thân, đây là hình ảnh của anh Tứ <img src=\"https://scontent.fhan3-2.fna.fbcdn.net/v/t1.6435-9/136142910_3671240586301430_6062072719418469868_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=833d8c&_nc_eui2=AeFpuebo3dCOt-fArif4Mld_-1ztD-AFshj7XO0P4AWyGMrier5Cx3GlRGJ4rbjvpcvt6KZPmuYEiu0NNQhaK_i0&_nc_ohc=wylBOJmzrYkQ7kNvgGBC3pA&_nc_oc=Adgq_4zLXzageSD7RGo-o5Uukq6tE0aRG_0BPpsaeE1Vid8IPPvms3XxAKyNBvGN9bw&_nc_zt=23&_nc_ht=scontent.fhan3-2.fna&_nc_gid=81G_SHnNDdqNGcYwROASFA&oh=00_AYFNgzRrEK2gIVlo2nYpD5LRMXrGhuMrzmz_ISqrKWq3QA&oe=68008D6F\"></img>'-----------------------page_content='Người phát triển ra VNGCloud AI Assistant (là một ChatBot Assistant nhằm hỗ trợ khách hàng của VNGCloud) và VKS là anh Dương Mạnh Cường một Software Engineer của VNGCloud, hiện còn độc thân, hình của Cường đây <img src=\" https://avatars.githubusercontent.com/u/40521173?v=4\"></img>'-----------------------"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:55:29.645776Z",
     "start_time": "2025-03-31T08:55:29.644410Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
