{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tool calling](https://python.langchain.com/docs/concepts/tool_calling/)\n",
    "\n",
    "###### Prerequisites\n",
    "- [Tools]()\n",
    "- [Chat Models]()\n",
    "\n",
    "\n",
    "## Overview\n",
    "- Many AI applications interact directly with humans. In these cases, it is appropriate for models to respond in natural language. But what about cases where we want a model to also interact directly with systems, such as databases or an API? These systems often have a particular input schema; for example, APIs frequently have a required payload structure. This need motivates the concept of tool calling. You can use tool calling to request model responses that match a particular schema.\n",
    "\n",
    "![](./images/01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key concepts\n",
    "- **Tool Creation**:  Use the `@tool` decorator to create a tool. A tool is an association between **a function** and **its schema**.\n",
    "- **Tool Binding**: The tool needs to be connected to a model that supports tool calling. This gives the model awareness of the tool and the associated input schema required by the tool.\n",
    "- **Tool Calling**: When appropriate, the model can decide to call a tool and ensure its response conforms to the tool's input schema.\n",
    "- **Tool Execution**: The tool can be executed using the arguments provided by the model.\n",
    "\n",
    "![](./images/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended usage\n",
    "- This pseudo-code illustrates the recommended workflow for using tool calling. Created tools are passed to .bind_tools() method as a list. This model can be called, as usual. If a tool call is made, model's response will contain the tool call arguments. The tool call arguments can be passed directly to the tool.\n",
    "  ```python\n",
    "  # Tool creation\n",
    "  tools = [my_tool]\n",
    "  # Tool binding\n",
    "  model_with_tools = model.bind_tools(tools)\n",
    "  # Tool calling \n",
    "  response = model_with_tools.invoke(user_input)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool creation\n",
    "- The recommended way to create a tool is using the `@tool` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    Returns:\n",
    "        int: the product of a and b\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool binding\n",
    "- The central concept to understand is that LangChain provides a standardized interface for connecting tools to models. The `.bind_tools()` method can be used to specify which tools are available for a model to call.\n",
    "- As a specific example, let's take a function `multiply` and bind it as a tool to a model that supports tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_to_dict(file_path):\n",
    "    env_dict = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # Remove whitespace and ignore comments or empty lines\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            # Split the line into key and value\n",
    "            key, value = line.split(\"=\", 1)\n",
    "            env_dict[key.strip()] = value.strip()\n",
    "    return env_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/mnt/Exdisk/git-cuongpiger/secret/work/vngcloud/ai-platform/env\"\n",
    "env_variables = load_env_to_dict(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    \"/mnt/Exdisk/git-cuongpiger/secret/work/vngcloud/ai-platform/vertex-ai-credential.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_bind_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool calling\n",
    "- A key principle of tool calling is that the model decides when to use a tool based on the input's relevance. The model doesn't always need to call a tool. For example, given an unrelated input, the model would not call the tool:\n",
    "\n",
    "  ![](./images/03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello world! What can I do for you today? ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.06103515625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.04150390625}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.083984375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.06298828125}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10986328125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.053466796875}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.25, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0849609375}], 'usage_metadata': {'prompt_token_count': 43, 'candidates_token_count': 14, 'total_token_count': 57, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.09774730035236903}, id='run-29cfdf05-7b97-4057-a065-88d6bb6d4182-0', usage_metadata={'input_tokens': 43, 'output_tokens': 14, 'total_tokens': 57})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_bind_tools.invoke(\"Hello world!\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result would be an `AIMessage` containing the model's response in natural language (e.g., \"Hello!\"). However, if we pass an input relevant to the tool, the model should choose to call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1240234375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09521484375}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1357421875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1025390625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.17578125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1142578125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0673828125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.07470703125}], 'usage_metadata': {'prompt_token_count': 49, 'candidates_token_count': 3, 'total_token_count': 52, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -2.3844768293201923e-07}, id='run-8b2d8448-3c12-40b3-8246-84ae433230d5-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '5ad85f03-83de-4f3c-bf6f-97b60cae614c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 49, 'output_tokens': 3, 'total_tokens': 52})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_bind_tools.invoke(\"What is 2 multiplied by 3?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the output result will be an `AIMessage`. But, if the tool was called, `result` will have a `tool_calls` attribute. This attribute includes everything needed to execute the tool, including the tool name and input arguments:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2.0, 'b': 3.0},\n",
       "  'id': '5ad85f03-83de-4f3c-bf6f-97b60cae614c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool execution\n",
    "- Tools implement the `Runnable` interface, which means that they can be invoked (e.g., `tool.invoke(args)`) directly.\n",
    "- LangGraph offers pre-built components (e.g., `ToolNode`) that will often invoke the tool in behalf of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "- When designing tools to be used by a model, it is important to keep in mind that:\n",
    "  - Models that have explicit **tool-calling APIs** will be better at tool calling than non-fine-tuned models.\n",
    "  - Models will perform better if the tools have well-chosen names and descriptions.\n",
    "  - Simple, narrowly scoped tools are easier for models to use than complex tools.\n",
    "  - Asking the model to select from a large list of tools poses challenges for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
